#### ***BERT-based User Review classification Model***
Text analysis can be performed using various language models such as BERT, GPT, and LLaMA. Among these, BERT is a bidirectional transformer model, which allows it to capture contextual information from both the left and right sides of a text. This bidirectional understanding enables a deeper and more accurate interpretation of language meaning.
BERT is particularly effective for short to medium-length text and excels at classification tasks. Since the goal of this project is to classify user reviews into five discrete rating categories (1–5 stars), BERT is a well-suited choice. Its strong contextual representation and proven performance in sentiment and text classification tasks make it ideal for predicting user review ratings accurately.


First Step：


<img width="2284" height="770" alt="image" src="https://github.com/user-attachments/assets/bd6d8095-63ae-46bf-83f0-fb68a8563e4a" />


